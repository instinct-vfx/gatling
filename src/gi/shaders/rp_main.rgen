#extension GL_GOOGLE_include_directive: require
#extension GL_EXT_ray_tracing: require
#extension GL_EXT_control_flow_attributes: require
#extension GL_EXT_shader_16bit_storage: require
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#extension GL_EXT_shader_explicit_arithmetic_types_int16: require
#extension GL_EXT_shader_explicit_arithmetic_types_int64: require
#ifdef REORDER_INVOCATIONS
#extension GL_EXT_buffer_reference: require
#extension GL_NV_shader_invocation_reorder: require
#endif

#include "rp_main_payload.glsl"
#include "rp_main_descriptors.glsl"
#include "colormap.glsl"

layout(location = PAYLOAD_INDEX_SHADE) rayPayloadEXT ShadeRayPayload rayPayload;
layout(location = PAYLOAD_INDEX_SHADOW) rayPayloadEXT ShadowRayPayload shadowRayPayload;

#ifdef REORDER_INVOCATIONS
layout(buffer_reference, hitobjectshaderrecordnv) buffer ShaderRecordBuffer
{
    uint closestHitShaderIndex;
    uint anyHitShaderIndex;
};
#endif

vec3 evaluate_sample(vec3 ray_origin,
                     vec3 ray_dir,
#ifdef RAND_4D
                     uvec4 rng_state)
#else
                     uint rng_state)
#endif
{
    rayPayload.throughput = vec3(1.0);
    rayPayload.bitfield   = 0;
    rayPayload.radiance   = vec3(0.0);
    rayPayload.rng_state  = rng_state;
    rayPayload.ray_origin = ray_origin;
    rayPayload.ray_dir    = ray_dir;

#if AOV_ID == AOV_ID_DEBUG_BOUNCES
    uint bounce = 0;
#endif

    // Correct clip plane curving by getting the hypothenuse length (our current ray)
    // from the adjacent edge (the forward vector) the angle between both.
    float cosConeAngle = dot(ray_dir, PC.cameraForward);
    vec2 clipRange = unpackHalf2x16(PC.clipRangePacked) / cosConeAngle;

    // Path trace
    uint maxBounces = PC.maxBouncesAndRrBounceOffset >> 16;

    [[loop]]
    while ((rayPayload.bitfield & 0x7FFFu) <= maxBounces)
    {
        // Closest hit shading
        rayPayload.neeContrib = vec3(0.0);

#ifdef REORDER_INVOCATIONS
        hitObjectNV hitObject;

        hitObjectTraceRayNV(
            hitObject,             // hit object
            sceneAS,               // top-level AS
            0,                     // rayFlags
            0xFF,                  // cullMask
            0,                     // sbtRecordOffset
            2,                     // sbtRecordStride
            0,                     // missIndex
            rayPayload.ray_origin, // ray origin
            clipRange.x,           // ray min range
            rayPayload.ray_dir,    // ray direction
            clipRange.y,           // ray max range
            PAYLOAD_INDEX_SHADE    // payload
        );

        uint reorderHint = 0xFFFFFFFFu;

        if (hitObjectIsHitNV(hitObject))
        {
            uvec2 handle = hitObjectGetShaderRecordBufferHandleNV(hitObject);
            reorderHint = ShaderRecordBuffer(handle).closestHitShaderIndex;
        }

        reorderThreadNV(hitObject, reorderHint, REORDER_HINT_BIT_COUNT);

        hitObjectExecuteShaderNV(hitObject, PAYLOAD_INDEX_SHADE);
#else
        traceRayEXT(
            sceneAS,               // top-level AS
            0,                     // rayFlags
            0xFF,                  // cullMask
            0,                     // sbtRecordOffset
            2,                     // sbtRecordStride
            0,                     // missIndex
            rayPayload.ray_origin, // ray origin
            clipRange.x,           // ray min range
            rayPayload.ray_dir,    // ray direction
            clipRange.y,           // ray max range
            PAYLOAD_INDEX_SHADE    // payload
        );
#endif

        // NEE shadow query
#ifdef NEXT_EVENT_ESTIMATION
#if SPHERE_LIGHT_COUNT > 0
        {
            shadowRayPayload.rng_state = rayPayload.rng_state;
            shadowRayPayload.shadowed = true; // Gets set to false by miss shader

            vec3 shadowRayOrigin = rayPayload.ray_origin; // actually not correct, but we compensate with tMin
            float lightDist = length(rayPayload.neeToLight);
            vec3 shadowRayDir = rayPayload.neeToLight / lightDist;

            // NV best practices recommends unconditional dispatch with tMin = tMax = 0.0
            bool traceRay = luminance(rayPayload.neeContrib) > 0.0001 && lightDist > 0.0;
            uint rayFlags = gl_RayFlagsTerminateOnFirstHitEXT | gl_RayFlagsSkipClosestHitShaderEXT;
            float tMin = traceRay ? 0.01 : 0.0; // FIXME: investigate resulting artifacts
            float tMax = traceRay ? lightDist : tMin;

            traceRayEXT(
                sceneAS,             // top-level acceleration structure
                rayFlags,            // rayFlags
                0xFF,                // cullMask
                1,                   // sbtRecordOffset (shadow test: use second hit group)
                2,                   // sbtRecordStride
                1,                   // missIndex (differs because of shadow test)
                shadowRayOrigin,     // ray origin
                tMin,                // ray min range
                shadowRayDir,        // ray direction
                tMax,                // ray max range
                PAYLOAD_INDEX_SHADOW // payload
            );

            bool addContrib = traceRay && !shadowRayPayload.shadowed;

            rayPayload.rng_state = shadowRayPayload.rng_state;
            rayPayload.radiance += rayPayload.neeContrib * float(addContrib);

#if AOV_ID == AOV_ID_DEBUG_NEE
            rayPayload.radiance = shadowRayPayload.shadowed ? vec3(1.0, 0.0, 0.0) : vec3(0.0, 1.0, 0.0);
            rayPayload.bitfield = 0xFFFFu;
#endif
        }
#endif
#endif

        clipRange = vec2(0.0, FLOAT_MAX); // Only clip primary rays

#if AOV_ID == AOV_ID_DEBUG_BOUNCES
        bounce++;
#endif
    }

#if AOV_ID == AOV_ID_DEBUG_BOUNCES
    return colormap_inferno(float(bounce) / float(maxBounces));
#endif

    // Radiance clamping
    vec3 radiance = vec3(rayPayload.radiance);
    float maxValue = max(radiance.r, max(radiance.g, radiance.b));
    if (maxValue > PC.maxSampleValue)
    {
        radiance *= PC.maxSampleValue / maxValue;
    }

    return max(vec3(0.0), radiance);
}

// Filter Importance Sampling of a Gauss kernel
// https://ieeexplore.ieee.org/document/4061554
// We use the Box-Muller transform to draw samples from the distribution.
// Also see: https://nvpro-samples.github.io/vk_mini_path_tracer/extras.html#gaussianfilterantialiasing
vec2 fisGauss(vec2 xi)
{
    float u1 = max(1e-38, xi.x); // needs to be in (0, 1]
    float u2 = xi.y; // in [0, 1]

    // https://academo.org/demos/gaussian-distribution/
    float sigma = 0.375; // NV tutorial and Cycles

    float r = sigma * sqrt(-2.0 * log(u1));
    float phi = 2.0 * PI * u2;

    return vec2(cos(phi), sin(phi)) * r;
}

void main()
{
#if AOV_ID == AOV_ID_DEBUG_CLOCK_CYCLES
    uint64_t start_cycle_count = clockARB();
#endif

    uvec2 pixel_pos = gl_LaunchIDEXT.xy;
    uint imageWidth = PC.imageDims & 0xFFFFu;
    uint imageHeight = PC.imageDims >> 16;

    uint pixel_index = pixel_pos.x + pixel_pos.y * imageWidth;

    vec3 camera_right = cross(PC.cameraForward, PC.cameraUp);
    float aspect_ratio = float(imageWidth) / float(imageHeight);

    float H = 1.0;
    float W = H * aspect_ratio;
    float d = H / (2.0 * tan(PC.cameraVFoV * 0.5));

    float WX = W / float(imageWidth);
    float HY = H / float(imageHeight);

    vec3 C = PC.cameraPosition + PC.cameraForward * d;
    vec3 L = C - camera_right * W * 0.5 - PC.cameraUp * H * 0.5;

    float inv_sample_count = 1.0 / float(PC.sampleCount);

    vec3 pixel_color = vec3(0.0, 0.0, 0.0);
    for (uint s = 0; s < PC.sampleCount; ++s)
    {
        uint sampleIndex = PC.sampleOffset + s;
#ifdef RAND_4D
        uvec4 rng_state = rng4d_init(pixel_pos.xy, sampleIndex);
        vec4 rand4 = rng4d_next(rng_state);
        vec2 rand2_xy = rand4.xy;
#else
        uint rng_state = rng_init(pixel_index, sampleIndex);
        vec2 rand2_xy = vec2(rng_next(rng_state), rng_next(rng_state));
#endif

        // Uniform pixel area sampling
        vec2 sampleOffset = rand2_xy;

#ifdef FILTER_IMPORTANCE_SAMPLING
        // Importance sample multi-pixel filtering kernel
        sampleOffset = vec2(0.5) + fisGauss(rand2_xy);
#endif

        vec3 P =
            L +
            (float(pixel_pos.x) + sampleOffset.x) * camera_right * WX +
            (float(pixel_pos.y) + sampleOffset.y) * PC.cameraUp * HY;

        vec3 rayOrigin = PC.cameraPosition;
        vec3 rayDir = normalize(P - rayOrigin);

        // Depth of Field
        // (cmp. RT Gems II; Boksansky's Reference PT)

#ifdef DEPTH_OF_FIELD
        if (PC.lensRadius > 0.0)
        {
#ifdef RAND_4D
            vec2 rand2_zw = rand4.zw;
#else
            vec2 rand2_zw = vec2(rng_next(rng_state), rng_next(rng_state));
#endif

            vec3 focalPoint = rayOrigin + rayDir * PC.focusDistance;
            vec2 apertureSample = sample_hemisphere(rand2_zw).xy * PC.lensRadius;

            rayOrigin += apertureSample.x * camera_right;
            rayOrigin += apertureSample.y * PC.cameraUp;

            rayDir = normalize(focalPoint - rayOrigin);
        }
#endif

        /* Beware: a single direction component must not be zero,
         * because we often take the inverse of the direction. */
        rayDir += vec3(equal(rayDir, vec3(0.0))) * FLOAT_MIN;

        /* Path trace sample and accumulate color. */
        vec3 sample_color = evaluate_sample(rayOrigin, rayDir, rng_state);
        pixel_color += sample_color * inv_sample_count;
    }

#if AOV_ID == AOV_ID_DEBUG_CLOCK_CYCLES
    float cycles_elapsed_norm = float(clockARB() - start_cycle_count) / float(UINT32_MAX);
    pixel_color = vec3(cycles_elapsed_norm, 0.0, 0.0);
#endif

#ifdef PROGRESSIVE_ACCUMULATION
    if (PC.sampleOffset > 0)
    {
      float inv_total_sample_count = 1.0 / float(PC.sampleOffset + PC.sampleCount);

      float weight_old = float(PC.sampleOffset) * inv_total_sample_count;
      float weight_new = float(PC.sampleCount) * inv_total_sample_count;

      pixel_color = weight_old * pixels[pixel_index].rgb + weight_new * pixel_color;
    }
#endif

    pixels[pixel_index] = vec4(pixel_color, 1.0);
}
